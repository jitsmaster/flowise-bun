{
    "description": "A simple LLM chain that uses Vectara to enable conversations with uploaded files",
    "nodes": [
        {
            "width": 300,
            "height": 574,
            "id": "chatOpenAI_0",
            "position": {
                "x": 581.1784360612766,
                "y": -229.3906666911439
            },
            "type": "customNode",
            "data": {
                "id": "chatOpenAI_0",
                "label": "ChatOpenAI",
                "version": 2,
                "name": "chatOpenAI",
                "type": "ChatOpenAI",
                "baseClasses": ["ChatOpenAI", "BaseChatModel", "BaseLanguageModel", "Runnable"],
                "category": "Chat Models",
                "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "chatOpenAI_0-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "options",
                        "options": [
                            {
                                "label": "gpt-4",
                                "name": "gpt-4"
                            },
                            {
                                "label": "gpt-4-0613",
                                "name": "gpt-4-0613"
                            },
                            {
                                "label": "gpt-4-32k",
                                "name": "gpt-4-32k"
                            },
                            {
                                "label": "gpt-4-32k-0613",
                                "name": "gpt-4-32k-0613"
                            },
                            {
                                "label": "gpt-3.5-turbo",
                                "name": "gpt-3.5-turbo"
                            },
                            {
                                "label": "gpt-3.5-turbo-0613",
                                "name": "gpt-3.5-turbo-0613"
                            },
                            {
                                "label": "gpt-3.5-turbo-16k",
                                "name": "gpt-3.5-turbo-16k"
                            },
                            {
                                "label": "gpt-3.5-turbo-16k-0613",
                                "name": "gpt-3.5-turbo-16k-0613"
                            }
                        ],
                        "default": "gpt-3.5-turbo",
                        "optional": true,
                        "id": "chatOpenAI_0-input-modelName-options"
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "step": 0.1,
                        "default": 0.9,
                        "optional": true,
                        "id": "chatOpenAI_0-input-temperature-number"
                    },
                    {
                        "label": "Max Tokens",
                        "name": "maxTokens",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-maxTokens-number"
                    },
                    {
                        "label": "Top Probability",
                        "name": "topP",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-topP-number"
                    },
                    {
                        "label": "Frequency Penalty",
                        "name": "frequencyPenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-frequencyPenalty-number"
                    },
                    {
                        "label": "Presence Penalty",
                        "name": "presencePenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-presencePenalty-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-basepath-string"
                    },
                    {
                        "label": "BaseOptions",
                        "name": "baseOptions",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-baseOptions-json"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Cache",
                        "name": "cache",
                        "type": "BaseCache",
                        "optional": true,
                        "id": "chatOpenAI_0-input-cache-BaseCache"
                    }
                ],
                "inputs": {
                    "modelName": "gpt-3.5-turbo",
                    "temperature": "0.6",
                    "maxTokens": "",
                    "topP": "",
                    "frequencyPenalty": "",
                    "presencePenalty": "",
                    "timeout": "",
                    "basepath": "",
                    "baseOptions": ""
                },
                "outputAnchors": [
                    {
                        "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
                        "name": "chatOpenAI",
                        "label": "ChatOpenAI",
                        "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 581.1784360612766,
                "y": -229.3906666911439
            },
            "dragging": false
        },
        {
            "width": 300,
            "height": 480,
            "id": "conversationalRetrievalQAChain_0",
            "position": {
                "x": 979.9713511176517,
                "y": 200.09513217589273
            },
            "type": "customNode",
            "data": {
                "id": "conversationalRetrievalQAChain_0",
                "label": "Conversational Retrieval QA Chain",
                "version": 2,
                "name": "conversationalRetrievalQAChain",
                "type": "ConversationalRetrievalQAChain",
                "baseClasses": ["ConversationalRetrievalQAChain", "BaseChain", "Runnable"],
                "category": "Chains",
                "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
                "inputParams": [
                    {
                        "label": "Return Source Documents",
                        "name": "returnSourceDocuments",
                        "type": "boolean",
                        "optional": true,
                        "id": "conversationalRetrievalQAChain_0-input-returnSourceDocuments-boolean"
                    },
                    {
                        "label": "Rephrase Prompt",
                        "name": "rephrasePrompt",
                        "type": "string",
                        "description": "Using previous chat history, rephrase question into a standalone question",
                        "warning": "Prompt must include input variables: {chat_history} and {question}",
                        "rows": 4,
                        "additionalParams": true,
                        "optional": true,
                        "default": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
                        "id": "conversationalRetrievalQAChain_0-input-rephrasePrompt-string"
                    },
                    {
                        "label": "Response Prompt",
                        "name": "responsePrompt",
                        "type": "string",
                        "description": "Taking the rephrased question, search for answer from the provided context",
                        "warning": "Prompt must include input variable: {context}",
                        "rows": 4,
                        "additionalParams": true,
                        "optional": true,
                        "default": "You are a helpful assistant. Using the provided context, answer the user's question to the best of your ability using the resources provided.\nIf there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.\n------------\n{context}\n------------\nREMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.",
                        "id": "conversationalRetrievalQAChain_0-input-responsePrompt-string"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "id": "conversationalRetrievalQAChain_0-input-model-BaseChatModel"
                    },
                    {
                        "label": "Vector Store Retriever",
                        "name": "vectorStoreRetriever",
                        "type": "BaseRetriever",
                        "id": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
                    },
                    {
                        "label": "Memory",
                        "name": "memory",
                        "type": "BaseMemory",
                        "optional": true,
                        "description": "If left empty, a default BufferMemory will be used",
                        "id": "conversationalRetrievalQAChain_0-input-memory-BaseMemory"
                    }
                ],
                "inputs": {
                    "model": "{{chatOpenAI_0.data.instance}}",
                    "vectorStoreRetriever": "{{vectara_0.data.instance}}",
                    "memory": "",
                    "returnSourceDocuments": true,
                    "rephrasePrompt": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
                    "responsePrompt": "You are a helpful assistant. Using the provided context, answer the user's question to the best of your ability using the resources provided.\nIf there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.\n------------\n{context}\n------------\nREMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm not sure.\" Don't try to make up an answer."
                },
                "outputAnchors": [
                    {
                        "id": "conversationalRetrievalQAChain_0-output-conversationalRetrievalQAChain-ConversationalRetrievalQAChain|BaseChain|Runnable",
                        "name": "conversationalRetrievalQAChain",
                        "label": "ConversationalRetrievalQAChain",
                        "type": "ConversationalRetrievalQAChain | BaseChain | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "selected": false,
            "dragging": false,
            "positionAbsolute": {
                "x": 979.9713511176517,
                "y": 200.09513217589273
            }
        },
        {
            "width": 300,
            "height": 535,
            "id": "vectara_0",
            "position": {
                "x": 199.28476672510158,
                "y": 177.63260741741112
            },
            "type": "customNode",
            "data": {
                "id": "vectara_0",
                "label": "Vectara",
                "version": 1,
                "name": "vectara",
                "type": "Vectara",
                "baseClasses": ["Vectara", "VectorStoreRetriever", "BaseRetriever"],
                "category": "Vector Stores",
                "description": "Upsert embedded data and perform similarity search upon query using Vectara, a LLM-powered search-as-a-service",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["vectaraApi"],
                        "id": "vectara_0-input-credential-credential"
                    },
                    {
                        "label": "File",
                        "name": "file",
                        "description": "File to upload to Vectara. Supported file types: https://docs.vectara.com/docs/api-reference/indexing-apis/file-upload/file-upload-filetypes",
                        "type": "file",
                        "optional": true,
                        "id": "vectara_0-input-file-file"
                    },
                    {
                        "label": "Metadata Filter",
                        "name": "filter",
                        "description": "Filter to apply to Vectara metadata. Refer to the <a target=\"_blank\" href=\"https://docs.flowiseai.com/vector-stores/vectara\">documentation</a> on how to use Vectara filters with Flowise.",
                        "type": "string",
                        "additionalParams": true,
                        "optional": true,
                        "id": "vectara_0-input-filter-string"
                    },
                    {
                        "label": "Sentences Before",
                        "name": "sentencesBefore",
                        "description": "Number of sentences to fetch before the matched sentence. Defaults to 2.",
                        "type": "number",
                        "additionalParams": true,
                        "optional": true,
                        "id": "vectara_0-input-sentencesBefore-number"
                    },
                    {
                        "label": "Sentences After",
                        "name": "sentencesAfter",
                        "description": "Number of sentences to fetch after the matched sentence. Defaults to 2.",
                        "type": "number",
                        "additionalParams": true,
                        "optional": true,
                        "id": "vectara_0-input-sentencesAfter-number"
                    },
                    {
                        "label": "Lambda",
                        "name": "lambda",
                        "description": "Improves retrieval accuracy by adjusting the balance (from 0 to 1) between neural search and keyword-based search factors.",
                        "type": "number",
                        "additionalParams": true,
                        "optional": true,
                        "id": "vectara_0-input-lambda-number"
                    },
                    {
                        "label": "Top K",
                        "name": "topK",
                        "description": "Number of top results to fetch. Defaults to 5",
                        "placeholder": "5",
                        "type": "number",
                        "additionalParams": true,
                        "optional": true,
                        "id": "vectara_0-input-topK-number"
                    },
                    {
                        "label": "MMR K",
                        "name": "mmrK",
                        "description": "The number of results to rerank if MMR is enabled.",
                        "placeholder": "50",
                        "type": "number",
                        "additionalParams": true,
                        "optional": true,
                        "id": "vectara_0-input-mmrK-number"
                    },
                    {
                        "label": "MMR Diversity Bias",
                        "name": "mmrDiversityBias",
                        "step": 0.1,
                        "description": "Diversity Bias parameter for MMR, if enabled. 0.0 means no diversiry bias, 1.0 means maximum diversity bias. Defaults to 0.0 (MMR disabled).",
                        "placeholder": "0.0",
                        "type": "number",
                        "additionalParams": true,
                        "optional": true,
                        "id": "vectara_0-input-mmrDiversityBias-number"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Document",
                        "name": "document",
                        "type": "Document",
                        "list": true,
                        "optional": true,
                        "id": "vectara_0-input-document-Document"
                    }
                ],
                "inputs": {
                    "document": "",
                    "filter": "",
                    "sentencesBefore": "",
                    "sentencesAfter": "",
                    "lambda": "",
                    "topK": "",
                    "mmrK": "",
                    "mmrDiversityBias": ""
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "options": [
                            {
                                "id": "vectara_0-output-retriever-Vectara|VectorStoreRetriever|BaseRetriever",
                                "name": "retriever",
                                "label": "Vectara Retriever",
                                "type": "Vectara | VectorStoreRetriever | BaseRetriever"
                            },
                            {
                                "id": "vectara_0-output-vectorStore-Vectara|VectorStore",
                                "name": "vectorStore",
                                "label": "Vectara Vector Store",
                                "type": "Vectara | VectorStore"
                            }
                        ],
                        "default": "retriever"
                    }
                ],
                "outputs": {
                    "output": "retriever"
                },
                "selected": false
            },
            "selected": false,
            "positionAbsolute": {
                "x": 199.28476672510158,
                "y": 177.63260741741112
            },
            "dragging": false
        }
    ],
    "edges": [
        {
            "source": "chatOpenAI_0",
            "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "target": "conversationalRetrievalQAChain_0",
            "targetHandle": "conversationalRetrievalQAChain_0-input-model-BaseChatModel",
            "type": "buttonedge",
            "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-model-BaseChatModel",
            "data": {
                "label": ""
            }
        },
        {
            "source": "vectara_0",
            "sourceHandle": "vectara_0-output-retriever-Vectara|VectorStoreRetriever|BaseRetriever",
            "target": "conversationalRetrievalQAChain_0",
            "targetHandle": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
            "type": "buttonedge",
            "id": "vectara_0-vectara_0-output-retriever-Vectara|VectorStoreRetriever|BaseRetriever-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
            "data": {
                "label": ""
            }
        }
    ]
}
